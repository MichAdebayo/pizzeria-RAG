# ğŸ• Pizzeria RAG - Assistant de Recherche Multi-Documents

Un systÃ¨me RAG (Retrieval-Augmented Generation) moderne pour interroger plusieurs menus de pizzerias avec Ollama et ChromaDB.

## ğŸš€ FonctionnalitÃ©s

- **RAG Multi-Documents**: Recherche simultanÃ©e dans plusieurs menus de pizzerias
- **Interface Moderne**: Chainlit et Gradio pour une expÃ©rience utilisateur optimale
- **Local-First**: Utilise Ollama pour les embeddings et LLM (pas de dÃ©pendance cloud)
- **Architecture Modulaire**: Code propre, maintenable et extensible
- **Processing Intelligent**: Extraction et indexation automatique des PDFs

## ğŸ› ï¸ Architecture

```
pizzeria-RAG/
â”œâ”€â”€ config/                 # Configuration centralisÃ©e
â”œâ”€â”€ data/                   # DonnÃ©es traitÃ©es et base vectorielle
â”œâ”€â”€ docs/raw_pdfs/          # Documents PDF sources
â”œâ”€â”€ processors/             # Traitement des documents
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ apps/              # Applications utilisateur
â”‚   â”‚   â”œâ”€â”€ chainlit_app.py    # Interface chat moderne
â”‚   â”‚   â””â”€â”€ gradio_app.py      # Interface web alternative
â”‚   â”œâ”€â”€ core/              # FonctionnalitÃ©s principales
â”‚   â”‚   â”œâ”€â”€ pipeline.py        # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ rag_engine.py      # Moteur RAG complet
â”‚   â”‚   â””â”€â”€ vector_store.py    # Gestion embeddings & ChromaDB
â”‚   â””â”€â”€ extractors/        # Extracteurs de contenu
```

## ğŸ“‹ PrÃ©requis

1. **Ollama** installÃ© et configurÃ©
2. **Python 3.9+**
3. **ModÃ¨les Ollama**:
   - `llama3.2:latest` (chat)
   - `mxbai-embed-large` (embeddings)

## ğŸ”§ Installation

1. **Cloner le projet**:
```bash
git clone <repository-url>
cd pizzeria-RAG
```

2. **CrÃ©er l'environnement virtuel**:
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou .venv\Scripts\activate  # Windows
```

3. **Installer les dÃ©pendances**:
```bash
pip install -r requirements.txt
```

4. **DÃ©marrer Ollama** (dans un terminal sÃ©parÃ©):
```bash
ollama serve
```

5. **TÃ©lÃ©charger les modÃ¨les**:
```bash
ollama pull llama3.2:latest
ollama pull mxbai-embed-large
```

## ğŸ¯ Utilisation

### Interface Chainlit (RecommandÃ©e)
```bash
./start_chainlit.sh
```
AccÃ¨s: http://localhost:8000

### Interface Gradio (Alternative)
```bash
./start_gradio.sh
```
AccÃ¨s: http://localhost:7860

### Utilisation directe en Python
```python
from src.core.rag_engine import LLMInterface

llm = LLMInterface()
result = llm.answer_question("Quelles pizzas vÃ©gÃ©tariennes avez-vous?")
print(result['answer'])
```

## ğŸ’¬ Exemples de Questions

- **GÃ©nÃ©rales**: "Quelles pizzas avez-vous?"
- **SpÃ©cifiques**: "Chez Anchor Pizza, quel est le prix de la Margherita?"
- **Comparatives**: "Comparez les prix entre Marco Fuso et Anchor Pizza"
- **DÃ©taillÃ©es**: "Quels sont les ingrÃ©dients du Triomphe vÃ©gÃ©?"

## ğŸ”§ Commandes SystÃ¨me (Chainlit)

- `/status` - Statut dÃ©taillÃ© du systÃ¨me
- `/documents` - Liste des documents disponibles
- `/process` - Traiter/retraiter les documents
- `/help` - Aide complÃ¨te

## ğŸ“ DonnÃ©es

Le systÃ¨me traite automatiquement les PDFs dans `docs/raw_pdfs/`:
- **Anchor Pizza**: Menu et services
- **Marco Fuso**: Recettes et techniques

Les donnÃ©es traitÃ©es sont stockÃ©es dans:
- `data/processed/` - JSONs structurÃ©s
- `data/vector_db/` - Base vectorielle ChromaDB

## âš™ï¸ Configuration

Modifiez `config/config.py` pour ajuster:
- ModÃ¨les Ollama utilisÃ©s
- ParamÃ¨tres de chunking
- TempÃ©rature du LLM
- Ports et endpoints

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants:

1. **Ollama non connectÃ©**:
   ```bash
   ollama serve
   curl http://localhost:11434/api/tags
   ```

2. **ModÃ¨les manquants**:
   ```bash
   ollama list
   ollama pull llama3.2:latest
   ollama pull mxbai-embed-large
   ```

3. **Documents non indexÃ©s**:
   - Utilisez `/process` dans Chainlit
   - Ou vÃ©rifiez `data/vector_db/`

4. **ProblÃ¨mes de performance**:
   - RÃ©duisez `chunk_size` dans la config
   - VÃ©rifiez la RAM disponible

## ğŸš€ DÃ©veloppement

### Structure du code:
- **Modulaire**: Chaque composant a sa responsabilitÃ©
- **Type Hints**: Code typÃ© pour une meilleure maintenance
- **Logging**: TraÃ§abilitÃ© complÃ¨te des opÃ©rations
- **Tests**: Framework pytest intÃ©grÃ©

### Ajouter de nouveaux documents:
1. Placer le PDF dans `docs/raw_pdfs/`
2. Ajouter la configuration dans `config/config.py`
3. Relancer le traitement via `/process`

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir `LICENSE` pour plus de dÃ©tails.

## ğŸ¤ Contribution

Les contributions sont bienvenues! Merci de:
1. Fork le projet
2. CrÃ©er une branche feature
3. Commit vos changements
4. Pousser vers la branche
5. Ouvrir une Pull Request

## ğŸ“ Support

En cas de problÃ¨me:
1. VÃ©rifiez la section DÃ©pannage
2. Consultez les logs de l'application
3. Ouvrez une issue sur GitHub

---

**DÃ©veloppÃ© avec â¤ï¸ pour une expÃ©rience RAG moderne et efficace**
